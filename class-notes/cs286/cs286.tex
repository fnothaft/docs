\documentclass[10pt]{article}
\topmargin=0.0in %length of margin at the top of the page (1 inch added by default)
\oddsidemargin=0.0in %length of margin on sides for odd pages
\evensidemargin=0in %length of margin on sides for even pages
\textwidth=6.5in %How wide you want your text to be
\marginparwidth=0.5in
\headheight=0pt %1in margins at top and bottom (1 inch is added to this value by default)
\headsep=0pt %Increase to increase white space in between headers and the top of the page
\textheight=9.1in %How tall the text body is allowed to be on each page

\usepackage{url}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{enumitem}

\begin{document}

\date{}
\title{CS286: Database Systems}

\maketitle

\section{Lecture 3---9/4/2014}

\subsection{R*}

\begin{itemize}
\item Assumptions:
\begin{itemize}
\item There are administrative causes behind distributed data
\item Network: unreliable transport, in-order, packets are intact
\item Independent node failure
\item Slow-ish network
\end{itemize}
\item Research goals:
\begin{itemize}
\item ``Site autonomy'': No centralized state or control
\begin{itemize}
\item Data you touch should determine the sites you talk to
\item ``Distributed system is a system that fails because a machine you've never heard of fails''
\item Load sharing and decentralization
\item Less communication
\item Harder to coordinate data consistency
\item More network connections beyond hub and spoke
\item Metadata management is harder
\end{itemize}
\item Location transparency $\rightarrow$ emulate a centralized DB
\item Don't assume much about the network or OS
\end{itemize}
\item Highlights:
\begin{itemize}
\item Query optimizer cost modeling
\item Data layouts $\rightarrow$ horizontal partitioning
\item Replication
\item Distribution
\item Query compilation---unclear as to balance between compilation overhead and work saving
\item Spent a lot of time talking about 2PC $\rightarrow$ presumed commit
\end{itemize}
\end{itemize}

\subsection{Gamma}

\begin{itemize}
\item Assumptions:
\begin{itemize}
\item Fast interconnect---hypercube, more network bandwidth than aggregate disk bandwidth
\item Shared nothing---no disk or memory sharing
\end{itemize}
\item Research goals:
\begin{itemize}
\item Scale
\end{itemize}
\item Highlights:
\begin{itemize}
\item Parallel hybrid-hash join
\item Chained declustering
\end{itemize}
\item Assess:
\begin{itemize}
\item Linear speedup + scale-up
\item Superlinear speedup due to minimized seek count at scale
\end{itemize}
\end{itemize}

\section{Lecture 4---9/9/2014}

\begin{itemize}
\item ACID
\begin{itemize}
\item Consistency is not what we typically think
\item Distributed systems: data has a consistent value across sites
\item Databases: data meets contract when transaction completes
\end{itemize}
\item Serializability mathematically gives atomicity and isolation
\item Logging gives atomicity and durability
\item Ordering:
\begin{itemize}
\item Determines outcome (unless operations are not associative and commutative)
\item Some things are commutable/associable
\item Ordering must be equivalent to some serializable order
\item Implicitly, this provides an API---people don't \emph{need} to reason about concurrency
\end{itemize}
\item What is storage?
\begin{itemize}
\item \emph{Spacial-temporal rendezvous makes everything work!!!!}
\end{itemize}
\item Want to avoid/undo conflicts in space and time
\begin{itemize}
\item \emph{Space:} Shared names
\item \emph{Time:} Ordering
\end{itemize}
\item 2PL: Provides a conflict serialized schedule
\begin{itemize}
\item Ordered by race for locks
\item Ordered by the end of the first phase (``lock point'')
\end{itemize}
\item Multi-version timestamp ordering
\begin{itemize}
\item Every transaction gets a timestamp---this is the only synchronization point
\item For every object:
\begin{itemize}
\item Writes generate a new version for an object
\item Reads annotate the version for the object
\end{itemize}
\end{itemize}
\end{itemize}

\section{Lecture 5---9/11/2014}

\begin{itemize}
\item Good graphs:
\begin{itemize}
\item Crossover points
\item Non-monotonicity
\item Good breadth of X
\item Smooth $\rightarrow$ variance was accounted for
\end{itemize}
\item Infinite resources:
\begin{itemize}
\item Why run infinite resources? Many people assumed infinite resources in their papers.
\item OCC wins because it allows higher parallelism, at the cost of restarting transactions
\item Blocking (2PL) performs well at start, low at the end. Why?
\begin{itemize}
\item Deadlock starts to cause performance to fail
\item Lock contention starts to cause transactions to get in each other's way
\item Locking is a feedback loop---it lengthens transaction time
\end{itemize}
\end{itemize}
\item Takeaways:
\begin{itemize}
\item MPL is a control variable---choose your infrastructure for your system
\end{itemize}
\item When do we have ``infinite'' resources?
\begin{itemize}
\item When we have user interaction (Computer $\gg$ human)
\item Vastly overprovisioned compute
\item Work is not going on inside the serving infrastructure (e.g., work is done by clients)
\end{itemize}
\end{itemize}

\subsection{What happens when you go distributed?}

\begin{itemize}
\item Why go distributed?
\begin{itemize}
\item Capacity (storage and throughput)
\item Low latency (tolerance)
\item Fault tolerance (durability vs. availability)
\end{itemize}
\item Techniques
\begin{itemize}
\item Sharding---split dataset across many nodes
\item Replication
\end{itemize}
\end{itemize}

\section{Lecture 6---9/16/2014}

\begin{itemize}
\item You need replication $\rightarrow$ resilience to failure
\item Tradeoff between replication and performance
\item NoSQL:
\begin{itemize}
\item Typically, a key-value store (data/programming model)
\item Typically distributed and sharded/partitioned
\item Usually weaker consistency model
\item No transactions/weak isolation model
\item ``Not MySQL'' $\rightarrow$ lots of work at AOL/etc. with MySQL on \texttt{memcached}
\item Typically OSS, not enterprise
\item ``Scalable'', especially incremental scale $\rightarrow$ improves organization/administration/ops
\item ``Evaporation'' of the DBA
\end{itemize}
\item Motivations:
\begin{itemize}
\item Bayou: I want to operate when disconnected
\item Dynamo: Nodes gonna fail
\end{itemize}
\item CAP theorem: if partitions occur, then we can either have consistency or availability
\begin{itemize}
\item Availability: As long as a client can access a server, I can access data (concurrent operations
don't need to communicate)
\item Consistency: ``linearizable registers'' $\rightarrow$ if I make a write, you can read my write
\end{itemize}
\end{itemize}

\section{Lecture 7---9/18/2014}

\begin{itemize}
\item In traditional database, have disk page with tuples stored at continuous offsets.
\begin{itemize}
\item Pointers (``slots'') are at end of page and point back to tuples.
\item Can then compress and compact by looking at slot pointers.
\item Fixed length fields stored in tuples
\item Tuples contain pointers to variable length fields
\end{itemize}
\item What changed between 1980 and 2010?
\begin{itemize}
\item CPUs 10,000$\times$ faster
\item Disk BW grew 100$\times$
\item Disk seek time improved 10$\times$
\end{itemize}
\item Specifically, gulf between disk performance and processor performance grew
\item Research methodology: if area is fairly static, change parameters and see what you can do
\item MonetDB
\begin{itemize}
\item Vector/block processing:
\end{itemize}
\item Traditional iterator processing model:
\begin{itemize}
\item Build a tree of operators that run on top of iterators
\item Algorithms have init method (set up state), get next (give me a tuple), and close operators
\item ``Pull'' model $\rightarrow$ data and control flow are coupled
\end{itemize}
\item ``Late materialization:'' query optimizer should defer reading columns until as late as it can
\item ``Invisible joins:'' joins that batch reordering
\begin{itemize}
\item Semijoin: Filter R for all items that have a match in S
\end{itemize}
\item Database cracking: opportunistically reorder blocks in order to improve performance
\end{itemize}

\section{Lecture 8---9/23/2014}

\begin{itemize}
\item Pre-relational data models:
\begin{itemize}
\item Network: objects + pointers
\item Hierarchical: nested sets
\end{itemize}
\item Then, \emph{the Relational Revolution}
\item But, persistent questioning:
\begin{itemize}
\item In the 80's, nested relational
\item Object-Oriented Database $\rightarrow$ 80's/90's
\item And then... XML
\end{itemize}
\item Why flatten into relations:
\begin{itemize}
\item Space efficient
\item Update/delete/inserts require work/care
\item Simple model and language
\item Data independence: physical and logical independence
\end{itemize}
\item When is the relational model a pain?
\begin{itemize}
\item Joins are expensive
\item Must know schema ahead of time
\item Read-only workloads are expensive
\item Programming language state
\end{itemize}
\item Engineering versus ``Found Structure'' $\rightarrow$ \emph{bricolage}
\begin{itemize}
\item Engineering $\rightarrow$ collaboration and communication
\item Found structure $\rightarrow$ exploratory data analytics
\end{itemize}
\item XML database history:
\begin{itemize}
\item WWW + search ate DB lunch
\item Let's query the internets!
\item DB $\times$ WWW $\times$ markup language people = pandemonium
\item 4 data models, 3 query languages, mostly overlap\dots
\end{itemize}
\item DB vendors kept up with the pace of research
\item How to encode XML:
\begin{itemize}
\item Native
\item Shred to relationable tables
\item Relational encoding of trees
\item Path/value encoding
\item Hybrids
\end{itemize}
\end{itemize}

\section{Lecture 9---9/25/2014}

\begin{itemize}
\item Few ways to provide/describe isolation; e.g., for a KV store:
\begin{itemize}
\item 2PL $\rightarrow$ mechanism
\item Avoid anomalies (no lost update, no dirty/fuzzy read) $\rightarrow$ anomaly prevention
\item Draw conflicts into graph (graph should have no cycle) $\rightarrow$ graph formalism
\item Every history is view equivalent to a serial history $\rightarrow$ equivalence formalism
\item If every program preserves an invariant, then every execution will preserve the invariant $\rightarrow$
integrity
\end{itemize}
\item Full isolation is expensive; let's go for weaker models
\item These descriptions don't imply equivalence:
\begin{itemize}
\item Can provide SG without cycle with OCC, OCC $\ne$ 2PL
\item Snapshot isolation $\rightarrow$ no anomalies, but does not preserve invariants
\end{itemize}
\item Strong vs. weak isolation: weaker implies more anomalies allowed, or more executions allowed
\item Conditions of \emph{reality}:
\begin{itemize}
\item Phantom: occurs when your program has a complex predicate, and when table modifications are
allowed (modifications can change predicate selections)
\begin{itemize}
\item Can solve with predicate locks (but no one does that)
\item Can solve with locks on indices, next key locks, etc\dots
\end{itemize}
\item \emph{Repeatable read}: in SQL, an isolation level where you can have phantoms, but everything
else is OK (IBM defines as full isolation, hence confusion\dots)
\item \emph{Fuzzy read}: short read locks, I read a single item multiple times and can see different
values
\item Statement-level atomicity: hold short read locks for the whole time I'm evaluating a statement
\item \texttt{select \dots \ for update}: hint that I'll grab locks later
\end{itemize}
\item Isolation levels:
\begin{enumerate}[start = 0]
\item Short duration write locks
\item Commit duration write locks
\item Commit duration write locks, short read locks
\item Full serializability
\end{enumerate}
\item Snapshot isolation: a good demonstration that you can beat anomalies (no lost update, no dirty
read, no fuzzy read, no phantoms), but not provide serializability
\end{itemize}

\section{Lecture 10---9/30/2014}

\begin{itemize}
\item Implementation:
\begin{itemize}
\item Concurrency control: 1 transaction at a time
\item All transactions are stored procedures; not interactive
\item Partition your workload (?)
\item Hot replicas: in relational world, replication is a backup strategy, not a runtime strategy
\item Weak consistency ``\emph{may}'' be interesting
\end{itemize}
\end{itemize}

\subsection{Hekaton}

\begin{itemize}
\item Built from ground-up to \emph{fit} into SQL Server:
\begin{itemize}
\item Limits design space
\item Must coexist with old systems (e.g., here, must have commit time in old system)
\end{itemize}
\item Much else is in other papers
\end{itemize}

\section{Lecture 11---10/2/2014}

\begin{itemize}
\item This guy fellow thinks that people aren't thinking enough about parametrized queries
\begin{itemize}
\item OLTP is pre-canned; OLAP isn't exactly
\item E.g., web forms
\end{itemize}
\item Query optimization, a primer:
\begin{itemize}
\item So, we want to select some keys from a table
\item There are many ways to execute most queries
\begin{itemize}
\item Joins are associative and commutative, so can be reordered
\item Many different algorithms for joins
\end{itemize}
\item If we have value distribution statistics, we can estimate the cost of a query plan
\item Problem is NP-hard, exponential in the number of tables
\item Getting a plan wrong can cause orders of magnitude performance differences
\begin{itemize}
\item But, there are often many OK plans
\end{itemize}
\end{itemize}
\end{itemize}

\subsection{Adaptive Query Processing}

\begin{itemize}
\item Eddies:
\begin{itemize}
\item \textsc{Now}-sort
\item Led to Inktomi
\item Led to River: adaptive parallel streaming/shuffle
\item Control: approximate query processing
\item Can structure work in many ways:
\begin{itemize}
\item Want to optimize for the expected amount of work
\end{itemize}
\end{itemize}
\end{itemize}

\subsection{Robust Query Processing}

\begin{itemize}
\item How can we make an optimizer more robust?
\begin{itemize}
\item Add a feedback loop and adapt
\item Make query plan ``pretty good'' even if your estimates are bad---you don't want the \emph{best}
plan, you want a good plan that has a very low chance of morphing into an \emph{bad} plan
\end{itemize}
\item Why?
\begin{itemize}
\item Bound your worst-case performance (don't break)
\item If you are robust to a metric, then you can use a cheap approach for collecting that metric
\item Predictable across versions
\end{itemize}
\item Approaches:
\begin{itemize}
\item L.C.: You materialized a full intermediate result
\item L.C. Eager M.: You add a materialization and look at the full intermediate approach
\item E.C.W.C.: Watch a pipe and remember the record IDs, do an anti-join
\item E.C.W.B.: Keep a buffer, so not as big as a materialization
\end{itemize}
\item Need dynamic programming algo to search the space
\end{itemize}

\section{Lecture 12---10/7/2014}

\begin{itemize}
\item Query optimization:
\begin{itemize}
\item We want to find the plan space
\item Estimate the cost!
\item And search (prune) that space
\end{itemize}
\item Should separate a plan space into a logical and physical space
\begin{itemize}
\item Logical space: logical operations
\item Physical space: access operations and disk layout (implementation)
\end{itemize}
\item If you put a rule, you can make things blow up badly
\item What happens if an optimizer doesn't exist? You need to take the optimizer that existed
before, and modify it for your new optimized implementation.
\item Cost estimation:
\begin{itemize}
\item Want to put together summary statistics
\item Specifically, we probably want to generate selectivity estimation for joins
\item Cardinality estimation for group-by's
\item Summary statistics are computed from the data, selectivity/cardinality estimation from summary
statistics
\item Cost estimation $=$ statistics
\end{itemize}
\item Logical plan space: SQL, XQuery, Pig, Datalog
\item Parallelism:
\begin{itemize}
\item How do I do a parallel database? How do I do joins/etc?
\item How do I allocate resources?
\end{itemize}
\item Physical strategies need to have a logical mapping
\item Can define rules mapping logical to logical, physical to logical
\item Search strategies:
\begin{itemize}
\item Bottom-up: data oriented, forward chaining
\item Top-down: goal oriented, backward chaining
\end{itemize}
\end{itemize}

\section{Lecture 13---10/14/2014}

\begin{itemize}
\item ``This is not computer science, it is \emph{sociology}!''
\item Ecosystem is important $\rightarrow$ how does industry impact research?
\item \textbf{TL; DR:}
\begin{itemize}
\item MapReduce: Introduced mid-query fault tolerance
\item DryadLINQ: ``We used cool language shit that we had at Microsoft.''
\end{itemize}
\item Early 2000's: What happened?
\begin{itemize}
\item ``\emph{The Cloud}'' $\rightarrow$ massive user bases
\item Scale-out data:
\begin{enumerate}
\item Data as a source of value $\rightarrow$ early offers for FB were based on value of network/data
\item Data has enormous scale and ``schema-on-use'' $\rightarrow$ disk is cheap, don't toss data away!
\end{enumerate}
\item Boom (late '90's) $\rightarrow$ bust (2001) $\rightarrow$ boom (2004) $\rightarrow$ bust (GFC)
$\rightarrow$ now
\item Revenue model changed: money is not made on software sales, rather, it is made on advertising
\item Also, RE: revenue: switched from \emph{sales} to \emph{subscription} $\rightarrow$ shift from
CapEx to OpEx
\item Aside: internet company developers (not enterprise developers) are driving design
\item Custom SW is not sufficiently valuable relative to other things, so give it away:
\begin{enumerate}
\item Network is value, not SW
\item Ops side arises: even if you \emph{had} FB's software, could you run Facebook?
\item Open source software attracts top talent
\item $E[engineer] = 2$ years: if everyone is going to leave in two years, don't have proprietary software
\item ``OOO and software reuse is dead''
\end{enumerate}
\item As a result, \emph{buy vs. build} decision is completely different
\end{itemize}
\item Huge implications on the DB community:
\begin{itemize}
\item \emph{Oracle as a punching bag} $\rightarrow$ ``All the bad things about Oracle must have arrived
out of bad DB research.''
\begin{itemize}
\item MySQL was also a dichotomous punching bag
\item Where was Postgres? Cool software, but performance is worse than MySQL.
\end{itemize}
\item We've changed the optimization function: programmer productivity is \#1 priority
\begin{itemize}
\item Initially, we must harness parallelism for developers!
\begin{itemize}
\item First, Google MapReduce
\item And, Hadoop @ Yahoo
\item Also, Scope at MSFT
\end{itemize}
\end{itemize}
\item Since 2004:
\begin{enumerate}
\item Parallel DBs were overpriced and slow
\item A lot of the MR workloads were SQL-ish:
\begin{itemize}
\item Hive
\item Pig
\end{itemize}
\item Clear OSS opportunity:
\begin{itemize}
\item Cloudera
\item Hortonworks
\item MapR
\item \dots
\end{itemize}
\item Google sponsors \emph{significant} education push around MapReduce
\item Hybrid workflows rise up
\end{enumerate}
\end{itemize}
\end{itemize}

\subsection{Questions}

\begin{enumerate}
\item Who should use the Hadoop ecosystem?
\begin{itemize}
\item HDFS: Is a pretty useful storage system.
\item Everything else:
\begin{itemize}
\item If you want to program MapReduce (e.g., custom UDFs), MR is a better platform...
\item What do you do once you get a result? With DBs, you can materialize it. With MR, you have many
ways to go from there. E.g., \emph{opportunistic vs. agile} pipelines. Assumes sophisticated developers
are using the system.
\item How much data should you have? If you've got a program that'll scale across multiple machines,
that's a good fit for Hadoop.
\item If you're using Hadoop, your jobs should probably be long running, and not terribly time critical.
\item Machine learning at scale?
\item How does Spark come in? Logical vs. physical fault tolerance is a nice thing to fall back on.
\end{itemize}
\end{itemize}
\item What should they pay?
\end{enumerate}

\subsection{DryadLINQ and .NET}

\begin{itemize}
\item LINQ is cool.
\item Unfortunately, it is in .NET\dots
\item What \emph{is} LINQ? $\rightarrow$ a functional DSL for collections
\item What \emph{in} .NET are they interested in? $\rightarrow$ Probably libraries for math/collections.
\item Debugging: provide a single node implementation that can be run locally.
\item Also have PLINQ $\rightarrow$ parallel LINQ on a single system; so node + processor parallelism
\end{itemize}

\section{Lecture 15---10/21/2014}

\begin{itemize}
\item Streaming queries was a giant fad:
\begin{itemize}
\item Language semantics issues are a big problem:
\begin{itemize}
\item Need a language that is rich enough that you can use, but
\item Easy enough that you can program
\item Declarative (calculus) vs. algebra languages
\item Complex event processing
\end{itemize}
\item Whole bucket of systems work:
\begin{itemize}
\item Minimize memory footprint
\item Scaling vs. number/complexity of queries
\item Adaptivity and load shedding
\item \emph{Surprisingly little} work on parallelism and fault tolerance
\item Distributed/service oriented fault tolerance
\end{itemize}
\item Theory:
\begin{itemize}
\item Using synopses/sketches
\item E.g., what happens if you can only look at a record once?
\end{itemize}
\item Practice:
\begin{itemize}
\item Streams are not ordered!
\item Therefore, need to \emph{reorder} streams.
\item People like to revoke data.
\item Few streams exist by themselves; we want to join against stored data.
\item Small \$\$\$\$, at least, so far.
\end{itemize}
\end{itemize}
\item Happened around the same time that XML was a huge fad
\item Industry stuff:
\begin{itemize}
\item Wall Street time series stuff (\texttt{Kx} for HFT)
\item Enterprise publish/subscribe services
\item Message queues: store and forward networks for transactional endpoints
\end{itemize}
\item Why don't transactions make sense? Concurrent, read heavy workloads.
\item Research projects:
\begin{itemize}
\item TelegraphCQ @ Berkeley
\item Aurora/Borealis @ MIT/Brandeis/Brown $\rightarrow$ started as dataflow language
\item STREAM @ Stanford
\end{itemize}
\item Language:
\begin{itemize}
\item Have both data and ordering $\rightarrow$ more than a relation
\item Have many-to-many mapping between records and time
\end{itemize}
\item Operators:
\begin{itemize}
\item Simple monotonic relational operators are fairly easy:
\begin{itemize}
\item Selection
\item Projection
\item Join
\end{itemize}
\item Nonmonotonic is harder:
\begin{itemize}
\item Temporal windows $\rightarrow$ specifically, when is the window done?
\item Aggregate
\end{itemize}
\end{itemize}
\end{itemize}

\section{Lecture 16---10/23/2014}

\begin{itemize}
\item Resilience:
\begin{itemize}
\item Flux uses replication
\item Spark Streaming uses lineage
\item Stream dataflows across multiple machines
\end{itemize}
\end{itemize}

\subsection{Flux}

\begin{itemize}
\item Problem: parallel, fault-tolerant, continuous queries ($\rightarrow$ data flow) with non-blocking
operators
\item Intuition: use replication (process pairs) and take-over on failure
\item How does it work?
\begin{enumerate}
\item Tuple comes in, and is streamed across two machines
\item Have replicated producer/consumer pairs, which run the exact same operations on the exact
same tuple streams
\item A consumer acks back to the \emph{other} producer
\end{enumerate}
\item What happens if a failure occurs?
\begin{enumerate}
\item The part of the system that \emph{isn't} failing stops getting acks
\item So, coordinator spin up a new machine
\item Coordinator tells \emph{every} node that node \texttt{n} is down
\item State movement:
\begin{enumerate}
\item I pause by \emph{quiescing} the user
\item I ``clone'' the ``brain'' by replicating the state
\end{enumerate}
\item Replay tuples through new machine
\end{enumerate}
\item Exchange operator can be parallelized
\item Invariants:
\begin{enumerate}
\item Don't lose a tuple
\item Don't duplicate a tuple
\end{enumerate}
\end{itemize}

\subsection{Spark Streaming}

\begin{itemize}
\item How do I Spark?
\begin{enumerate}
\item Input stage takes tuples, and lumps them into batches
\item Per batch, I create an RDD as part of my \emph{D-Stream}
\item I chain operators on top of these RDDs, which give me new RDDs. My operators are:
\begin{itemize}
\item Stateless
\item Deterministic
\item Short
\end{itemize}
\end{enumerate}
\end{itemize}

\end{document}
